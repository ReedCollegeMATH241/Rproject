---
title: "R Twitter Sentiment Analysis"
output:
  html_document:
  keep_md: yes
---
## Math 241 Term Project

### The Problem
The problem I decided to investigate is the question of how much Portland's famously crumby weather affects the sentiments expressed in tweets about the city.

## Disclaimer
I did not have enough data to actually try to attempt making a correlation between 

### Motivation
Twitter has become a ubiquitous means of self-expression which is entirely public. Thus more and more it has become a source of information about its users. At this point it has become so ubiquitous that nightly news often cites twitter data for vox populi type reporting. Working in media research this past summer I found that statistics about twitter were often used by producers to get a sense for audience engagement. However, many of these statistics were very basic like day-over-day percent-change in followers, numbers of retweets, and etc. These are basic reliable statistics, but in both journalism and consumer research there is also a lot of interest in getting a good cross-sectional read on what twitter users think about various subjects. And doing this computationally is a major challenge which ties into a number of areas which are attracting a lot of attention in data driven industries. 

One of these areas is sentiment analysis, which is an attempt to extrapolate some sort of summary of the feelings expressed in a unit of text. The sort of initial compromise which the problem requires that one make is the adoption of a metric for sentiment. Of course this is a challenge because even from person to person the perceived sentiment in a text is going to vary. This project is essentially an investigation of some basic methods of sentiment analysis, methods that rely on publicly shared algorithms. On the other side of the spectrum there are a number of commercial services like IBM's Alchemy API that provide the results of far more sophisticated methods. 

### Approach

First I settle on one of the options for sentiment analysis. As mentioned before there is a whole range of sophistication when it comes to sentiment analysis. I chose to go with the `qdap` packageâ€™s polarity, because the [documentation](http://trinker.github.io/qdap/vignettes/qdap_vignette.html#polarity) is excellent in terms of describing the methods used. I will also try using the `sentiment` package, which appears to be a little smarter but is not as well documented. I am not necessarily expecting to get valid data, and this decision may lead to my getting invalid data. However, if I do get invalid data I would rather understand the reasons why then not, so `qdap`'s sentiment analysis should allow me to make judgements about how the algorithm is working. 

#### Data Acquisition
Collect data using the R package _twitteR_ `searchTwitter('Portland',since=start.date, until=end.date ,geocode=geocode)` with the geocode being provided by the _ggmap_ package's `geocode('Portland,Or')` function and `start.date` and `end.date` being dates one day apart.

#### Explore data. 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
source('functions.R')
twits<-read.csv('./Twitter/2015-05-02.csv')
options(mc.cores=1)
dl<-dm(twits)
datatable(dl[,1:2])
```

#### Initial Observations
Reading from a csv file which was the writeout of a `twListToDF` call has removed a certain amount of data. I am not exactly sure why this is but various emoji's and the like have been removed. In order to avoid this one might try a different storage medium. For example one could try using the `twitteR` package's `search_twitter_and_store` command to store to a database. 

Looking at the content of the tweets, it's clear that the sentiment analysis is going to be difficult, since many of the tweets are just declarative sentences. This is due to a flaw inherent in the project's design, which is that we lack the sophistication to select tweets where people are expressing opinions. One thought as for how that might be done is to use the statusSource field provided in the lists obtained from the `twitteR` packages `searchTwitter` function, in order to eliminate generic tweets sent from applications.

Another minor problem is the lack of sentence structure. On the one hand, `qdap` relies heavily on a regular sentence structure to apply its functions, however one will almost never get that with twitter data. So it can't be helped. The `polarity` function which we will be using expects whole sentences, but right now we have whole tweets for input. However, after reviewing the theory behind how the function, it seems to turn it into sentences will lead to an inevitable loss of data. On the other hand, the `sentiment` package will not have any problems with this.

#### Basic Analysis

Now I am going to run the two basic algorithms. And compare their outputs, first we will look at a datatable produced by the `sentiment` package. Then at a plot of the polarities in the `qdap` package.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
setSentiment<-function(dl){
dl$text<-lapply(dl$text,gsub, pattern='^[[:punct:]]',replacement='')%>%
  lapply(gsub, pattern='^[[:space:]]',replacement='')
dl %<>% subset(!(text==''))
dl$sentiment<-classify_polarity(dl$text,algorithm = 'bayes')[,4]
dl$positiveScore<-classify_polarity(dl$text,algorithm = 'bayes')[,1]
dl$negativeScore<-classify_polarity(dl$text,algorithm = 'bayes')[,2]
dl
}
dl<-setSentiment(dl)
dl
datatable(dl[,c(2,18,19,20)])
```
```{r, out.width = '\\maxwidth',out.height='600px',echo=FALSE, warning=FALSE, message=FALSE}
corp<-Corpus(VectorSource(dl$text))%>%
  tm_map(sent_detect)
rm <- as.data.frame(corp)%>%
  sentSplit('text')%>%na.omit
poldat <- with(rm, polarity(rm, text))
plot(poldat)
```


Based off these results, neither the `sentiment` nor the `qdap` package have provided very reliable results. But the sentiment package has the benefit of being easier to interpret and easier to use. Despite the nicety of `qdap`'s documentation it is too sensitive and specialized a package for use on this sort of data. However, the sentiment analysis is dissapointing, the `negativeScore` on the tenth tweet in the above table is a really strong indication of the package's unreliability. Now I actually have a small enough data set that I could potentially use the free alchemyAPI to do the sentiment analysis. However, I do not know how to integrate its functionality with R so it is unfeasible. As a test case I did run the first few items through the API and it decided the first four tweets in the above list were positive.

### Analysis
Since the sentiment data is unreliable, and I can only pull twitter data from the last 7 days. I am not going to draw any conclusions about how the weather affects how Portland's tweeters tweet about the city.
